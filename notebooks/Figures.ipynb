{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "sys.path.insert(0,'../code/')\n",
    "from shared import *\n",
    "import pandas as pd\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_features = pd.read_csv('/home/alex/Desktop/kmeans_feature_averages.csv').drop(['Unnamed: 0'],axis=1)\n",
    "k_weights = pd.read_csv('/home/alex/Desktop/kmeans_weight_averages.csv').drop(['Unnamed: 0'],axis=1)\n",
    "m_features = pd.read_csv('/home/alex/Desktop/milp_feature_averages.csv').drop(['Unnamed: 0'],axis=1)\n",
    "m_weights = pd.read_csv('/home/alex/Desktop/milp_weight_averages.csv').drop(['Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny = pd.read_csv('/home/alex/Isabelle/data/NY_2000_NEW.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_weights['incpc'] = ''\n",
    "k_weights['# tracts'] = ''\n",
    "k_features['# tracts'] = 0\n",
    "for i in range(len(k_weights)):\n",
    "    tracts = literal_eval(k_weights.iat[i,8])\n",
    "    chgs = ny[ny.trtid.isin(tracts)]\n",
    "    k_features.iat[i,8] = \"%.2f\" % (np.median(chgs.incpc.values))\n",
    "    k_features.iat[i,9] = len(chgs)\n",
    "    \n",
    "m_weights['incpc'] = ''\n",
    "m_weights['# tracts'] = ''\n",
    "m_features['# tracts'] = 0\n",
    "for i in range(len(m_weights)):\n",
    "    tracts = literal_eval(m_weights.iat[i,8])\n",
    "    chgs = ny[ny.trtid.isin(tracts)]\n",
    "    m_features.iat[i,8] = \"%.2f\" % (np.median(chgs.incpc.values))\n",
    "    m_features.iat[i,9] = len(chgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrllrrrrrl}\n",
      "\\toprule\n",
      " k &  model &  val & \\# tracts &   prof &   col &  flabf &  multi &   own & incpc \\\\\n",
      "\\midrule\n",
      " 2 &      1 &  ftr &       83 &   1.02 &  0.99 &   0.80 &   0.48 &  0.44 &  0.56 \\\\\n",
      " 2 &      1 &  wgt &          &   0.45 &  0.27 &  -0.27 &  -0.04 &  0.07 &       \\\\\n",
      " 2 &      2 &  ftr &      153 &  -0.56 & -0.54 &  -0.43 &  -0.26 & -0.24 & -0.35 \\\\\n",
      " 2 &      2 &  wgt &          &   0.28 &  0.35 &  -0.25 &   0.15 &  0.14 &       \\\\\n",
      " 3 &      1 &  ftr &        8 &   2.83 &  2.84 &   2.19 &   2.98 &  2.72 &  2.05 \\\\\n",
      " 3 &      1 &  wgt &          & -23.16 &  6.16 &  10.83 &  -2.12 &  0.57 &       \\\\\n",
      " 3 &      2 &  ftr &      135 &  -0.62 & -0.63 &  -0.53 &  -0.28 & -0.29 & -0.52 \\\\\n",
      " 3 &      2 &  wgt &          &   0.26 &  0.47 &  -0.34 &   0.17 &  0.15 &       \\\\\n",
      " 3 &      3 &  ftr &       93 &   0.66 &  0.67 &   0.58 &   0.15 &  0.19 &  0.45 \\\\\n",
      " 3 &      3 &  wgt &          &   0.50 &  0.17 &  -0.16 &   0.33 &  0.12 &       \\\\\n",
      " 4 &      1 &  ftr &      137 &  -0.58 & -0.60 &  -0.47 &  -0.22 & -0.23 & -0.48 \\\\\n",
      " 4 &      1 &  wgt &          &   0.25 &  0.40 &  -0.20 &   0.50 &  0.30 &       \\\\\n",
      " 4 &      2 &  ftr &       90 &   0.67 &  0.70 &   0.60 &   0.15 &  0.20 &  0.46 \\\\\n",
      " 4 &      2 &  wgt &          &   0.51 &  0.15 &  -0.16 &   0.32 &  0.12 &       \\\\\n",
      " 4 &      3 &  ftr &        8 &   2.83 &  2.84 &   2.19 &   2.98 &  2.72 &  2.05 \\\\\n",
      " 4 &      3 &  wgt &          & -23.16 &  6.16 &  10.83 &  -2.12 &  0.57 &       \\\\\n",
      " 4 &      4 &  ftr &        1 &  -3.93 & -3.41 &  -7.43 &  -7.48 & -8.11 & -1.74 \\\\\n",
      " 4 &      4 &  wgt &          &   0.00 &  0.00 &   0.00 &   0.00 &  0.00 &       \\\\\n",
      " 5 &      1 &  ftr &       79 &   0.17 &  0.18 &   0.26 &   0.10 &  0.22 &  0.21 \\\\\n",
      " 5 &      1 &  wgt &          &   0.51 &  0.46 &  -0.05 &   0.23 &  0.18 &       \\\\\n",
      " 5 &      2 &  ftr &      114 &  -0.67 & -0.69 &  -0.54 &  -0.28 & -0.29 & -0.58 \\\\\n",
      " 5 &      2 &  wgt &          &   0.00 &  0.00 &   0.00 &   0.00 &  0.00 &       \\\\\n",
      " 5 &      3 &  ftr &       34 &   1.30 &  1.32 &   0.91 &   0.23 &  0.05 &  0.87 \\\\\n",
      " 5 &      3 &  wgt &          &   0.10 &  0.56 &  -0.06 &   0.26 &  0.33 &       \\\\\n",
      " 5 &      4 &  ftr &        1 &  -3.93 & -3.41 &  -7.43 &  -7.48 & -8.11 & -1.74 \\\\\n",
      " 5 &      4 &  wgt &          & -23.16 &  6.16 &  10.83 &  -2.12 &  0.57 &       \\\\\n",
      " 5 &      5 &  ftr &        8 &   2.83 &  2.84 &   2.19 &   2.98 &  2.72 &  2.05 \\\\\n",
      " 5 &      5 &  wgt &          &   0.51 & -0.03 &  -0.36 &   0.48 &  0.04 &       \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k_features['val'] = 'ftr'\n",
    "k_features = k_features[['k', 'f', 'model', 'val', '# tracts','prof', 'col', 'flabf', 'multi', 'own', 'incpc']]\n",
    "k_weights['val'] = 'wgt'\n",
    "k_weights = k_weights[['k', 'f', 'model', 'val', '# tracts', 'prof', 'col', 'flabf', 'multi', 'own', 'incpc']]\n",
    "k_means = pd.concat([k_weights,k_features])\n",
    "k_means = k_means.sort_values(by=['k','f','model','val'])\n",
    "k_means = k_means[k_means.f == 5]\n",
    "k_means = k_means.drop(['f'],axis=1)\n",
    "k_means = k_means.round(2)\n",
    "print(k_means.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrllrrrrrl}\n",
      "\\toprule\n",
      " k &  model &  val & \\# tracts &  prof &   col &  flabf &  multi &   own & incpc \\\\\n",
      "\\midrule\n",
      " 2 &      1 &  ftr &      100 & -0.02 & -0.01 &   0.06 &   0.01 &  0.01 &  0.01 \\\\\n",
      " 2 &      1 &  wgt &          &  0.00 &  0.00 &   0.00 &   0.00 &  0.21 &       \\\\\n",
      " 2 &      2 &  ftr &      136 &  0.02 &  0.00 &  -0.05 &  -0.01 & -0.01 &  -0.5 \\\\\n",
      " 2 &      2 &  wgt &          &  0.54 &  0.28 &   0.00 &   0.40 &  0.15 &       \\\\\n",
      " 3 &      1 &  ftr &       68 & -0.04 & -0.06 &  -0.05 &  -0.15 & -0.10 &  0.41 \\\\\n",
      " 3 &      1 &  wgt &          &  0.38 &  0.23 &   0.00 &   1.33 &  0.00 &       \\\\\n",
      " 3 &      2 &  ftr &       79 &  0.16 &  0.13 &   0.17 &   0.05 &  0.02 &     0 \\\\\n",
      " 3 &      2 &  wgt &          &  0.00 &  0.04 &   0.00 &   0.00 &  0.20 &       \\\\\n",
      " 3 &      3 &  ftr &       89 & -0.11 & -0.06 &  -0.12 &   0.07 &  0.06 & -0.59 \\\\\n",
      " 3 &      3 &  wgt &          &  0.99 &  0.04 &   0.00 &   0.12 &  0.00 &       \\\\\n",
      " 4 &      1 &  ftr &       64 & -0.05 & -0.04 &  -0.09 &  -0.13 &  0.02 & -0.44 \\\\\n",
      " 4 &      1 &  wgt &          &  0.28 &  0.00 &   0.02 &   0.65 &  0.38 &       \\\\\n",
      " 4 &      2 &  ftr &       69 & -0.16 & -0.11 &  -0.11 &   0.02 & -0.04 & -0.65 \\\\\n",
      " 4 &      2 &  wgt &          &  1.32 &  0.00 &   0.00 &   0.00 &  0.00 &       \\\\\n",
      " 4 &      3 &  ftr &       53 &  0.20 &  0.18 &   0.24 &   0.11 &  0.11 & -0.13 \\\\\n",
      " 4 &      3 &  wgt &          &  0.02 &  0.28 &   0.00 &   0.00 &  0.09 &       \\\\\n",
      " 4 &      4 &  ftr &       50 &  0.07 &  0.02 &   0.01 &   0.02 & -0.09 &  0.73 \\\\\n",
      " 4 &      4 &  wgt &          &  0.04 &  0.36 &   0.00 &   0.41 &  0.34 &       \\\\\n",
      " 5 &      1 &  ftr &       46 &  0.08 &  0.15 &  -0.04 &  -0.14 & -0.09 &  0.16 \\\\\n",
      " 5 &      1 &  wgt &          &  0.52 &  0.19 &   0.00 &   0.00 &  0.00 &       \\\\\n",
      " 5 &      2 &  ftr &       48 & -0.20 & -0.20 &  -0.13 &  -0.05 & -0.04 & -0.69 \\\\\n",
      " 5 &      2 &  wgt &          &  0.11 &  0.00 &   0.00 &   0.78 &  2.04 &       \\\\\n",
      " 5 &      3 &  ftr &       33 & -0.22 & -0.27 &  -0.19 &   0.04 & -0.17 & -0.57 \\\\\n",
      " 5 &      3 &  wgt &          &  0.73 &  1.47 &   0.00 &   0.30 &  0.99 &       \\\\\n",
      " 5 &      4 &  ftr &       53 &  0.20 &  0.21 &   0.17 &   0.02 &  0.08 & -0.15 \\\\\n",
      " 5 &      4 &  wgt &          &  0.30 &  0.00 &   0.27 &   0.32 &  0.31 &       \\\\\n",
      " 5 &      5 &  ftr &       56 &  0.04 &  0.01 &   0.10 &   0.12 &  0.13 &  0.02 \\\\\n",
      " 5 &      5 &  wgt &          &  0.00 &  0.00 &   0.00 &   0.00 &  0.00 &       \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m_features['val'] = 'ftr'\n",
    "m_features = m_features[['k', 'f', 'model', 'val', '# tracts','prof', 'col', 'flabf', 'multi', 'own', 'incpc']]\n",
    "m_weights['val'] = 'wgt'\n",
    "m_weights = m_weights[['k', 'f', 'model', 'val', '# tracts','prof', 'col', 'flabf', 'multi', 'own', 'incpc']]\n",
    "m_means = pd.concat([m_weights,m_features])\n",
    "m_means = m_means.sort_values(by=['k','f','model','val'])\n",
    "m_means = m_means[m_means.f == 5]\n",
    "m_means = m_means.drop(['f'],axis=1)\n",
    "m_means = m_means.round(2)\n",
    "print(m_means.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrllrrrrrllrrrrrl}\n",
      "\\toprule\n",
      " k &  model &  val & \\# tracts &   prof &   col &  flabf &  multi &   own & incpc & \\# tracts &  prof &   col &  flabf &  multi &   own & incpc \\\\\n",
      "\\midrule\n",
      " 2 &      1 &  ftr &       83 &   1.02 &  0.99 &   0.80 &   0.48 &  0.44 &  0.56 &      100 & -0.02 & -0.01 &   0.06 &   0.01 &  0.01 &  0.01 \\\\\n",
      " 2 &      1 &  wgt &          &   0.45 &  0.27 &  -0.27 &  -0.04 &  0.07 &       &          &  0.00 &  0.00 &   0.00 &   0.00 &  0.21 &       \\\\\n",
      " 2 &      2 &  ftr &      153 &  -0.56 & -0.54 &  -0.43 &  -0.26 & -0.24 & -0.35 &      136 &  0.02 &  0.00 &  -0.05 &  -0.01 & -0.01 &  -0.5 \\\\\n",
      " 2 &      2 &  wgt &          &   0.28 &  0.35 &  -0.25 &   0.15 &  0.14 &       &          &  0.54 &  0.28 &   0.00 &   0.40 &  0.15 &       \\\\\n",
      " 3 &      1 &  ftr &        8 &   2.83 &  2.84 &   2.19 &   2.98 &  2.72 &  2.05 &       68 & -0.04 & -0.06 &  -0.05 &  -0.15 & -0.10 &  0.41 \\\\\n",
      " 3 &      1 &  wgt &          & -23.16 &  6.16 &  10.83 &  -2.12 &  0.57 &       &          &  0.38 &  0.23 &   0.00 &   1.33 &  0.00 &       \\\\\n",
      " 3 &      2 &  ftr &      135 &  -0.62 & -0.63 &  -0.53 &  -0.28 & -0.29 & -0.52 &       79 &  0.16 &  0.13 &   0.17 &   0.05 &  0.02 &     0 \\\\\n",
      " 3 &      2 &  wgt &          &   0.26 &  0.47 &  -0.34 &   0.17 &  0.15 &       &          &  0.00 &  0.04 &   0.00 &   0.00 &  0.20 &       \\\\\n",
      " 3 &      3 &  ftr &       93 &   0.66 &  0.67 &   0.58 &   0.15 &  0.19 &  0.45 &       89 & -0.11 & -0.06 &  -0.12 &   0.07 &  0.06 & -0.59 \\\\\n",
      " 3 &      3 &  wgt &          &   0.50 &  0.17 &  -0.16 &   0.33 &  0.12 &       &          &  0.99 &  0.04 &   0.00 &   0.12 &  0.00 &       \\\\\n",
      " 4 &      1 &  ftr &      137 &  -0.58 & -0.60 &  -0.47 &  -0.22 & -0.23 & -0.48 &       64 & -0.05 & -0.04 &  -0.09 &  -0.13 &  0.02 & -0.44 \\\\\n",
      " 4 &      1 &  wgt &          &   0.25 &  0.40 &  -0.20 &   0.50 &  0.30 &       &          &  0.28 &  0.00 &   0.02 &   0.65 &  0.38 &       \\\\\n",
      " 4 &      2 &  ftr &       90 &   0.67 &  0.70 &   0.60 &   0.15 &  0.20 &  0.46 &       69 & -0.16 & -0.11 &  -0.11 &   0.02 & -0.04 & -0.65 \\\\\n",
      " 4 &      2 &  wgt &          &   0.51 &  0.15 &  -0.16 &   0.32 &  0.12 &       &          &  1.32 &  0.00 &   0.00 &   0.00 &  0.00 &       \\\\\n",
      " 4 &      3 &  ftr &        8 &   2.83 &  2.84 &   2.19 &   2.98 &  2.72 &  2.05 &       53 &  0.20 &  0.18 &   0.24 &   0.11 &  0.11 & -0.13 \\\\\n",
      " 4 &      3 &  wgt &          & -23.16 &  6.16 &  10.83 &  -2.12 &  0.57 &       &          &  0.02 &  0.28 &   0.00 &   0.00 &  0.09 &       \\\\\n",
      " 4 &      4 &  ftr &        1 &  -3.93 & -3.41 &  -7.43 &  -7.48 & -8.11 & -1.74 &       50 &  0.07 &  0.02 &   0.01 &   0.02 & -0.09 &  0.73 \\\\\n",
      " 4 &      4 &  wgt &          &   0.00 &  0.00 &   0.00 &   0.00 &  0.00 &       &          &  0.04 &  0.36 &   0.00 &   0.41 &  0.34 &       \\\\\n",
      " 5 &      1 &  ftr &       79 &   0.17 &  0.18 &   0.26 &   0.10 &  0.22 &  0.21 &       46 &  0.08 &  0.15 &  -0.04 &  -0.14 & -0.09 &  0.16 \\\\\n",
      " 5 &      1 &  wgt &          &   0.51 &  0.46 &  -0.05 &   0.23 &  0.18 &       &          &  0.52 &  0.19 &   0.00 &   0.00 &  0.00 &       \\\\\n",
      " 5 &      2 &  ftr &      114 &  -0.67 & -0.69 &  -0.54 &  -0.28 & -0.29 & -0.58 &       48 & -0.20 & -0.20 &  -0.13 &  -0.05 & -0.04 & -0.69 \\\\\n",
      " 5 &      2 &  wgt &          &   0.00 &  0.00 &   0.00 &   0.00 &  0.00 &       &          &  0.11 &  0.00 &   0.00 &   0.78 &  2.04 &       \\\\\n",
      " 5 &      3 &  ftr &       34 &   1.30 &  1.32 &   0.91 &   0.23 &  0.05 &  0.87 &       33 & -0.22 & -0.27 &  -0.19 &   0.04 & -0.17 & -0.57 \\\\\n",
      " 5 &      3 &  wgt &          &   0.10 &  0.56 &  -0.06 &   0.26 &  0.33 &       &          &  0.73 &  1.47 &   0.00 &   0.30 &  0.99 &       \\\\\n",
      " 5 &      4 &  ftr &        1 &  -3.93 & -3.41 &  -7.43 &  -7.48 & -8.11 & -1.74 &       53 &  0.20 &  0.21 &   0.17 &   0.02 &  0.08 & -0.15 \\\\\n",
      " 5 &      4 &  wgt &          & -23.16 &  6.16 &  10.83 &  -2.12 &  0.57 &       &          &  0.30 &  0.00 &   0.27 &   0.32 &  0.31 &       \\\\\n",
      " 5 &      5 &  ftr &        8 &   2.83 &  2.84 &   2.19 &   2.98 &  2.72 &  2.05 &       56 &  0.04 &  0.01 &   0.10 &   0.12 &  0.13 &  0.02 \\\\\n",
      " 5 &      5 &  wgt &          &   0.51 & -0.03 &  -0.36 &   0.48 &  0.04 &       &          &  0.00 &  0.00 &   0.00 &   0.00 &  0.00 &       \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([k_means,m_means[['# tracts','prof', 'col', 'flabf', 'multi', 'own','incpc']]],axis=1).to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
